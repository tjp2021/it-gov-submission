/**
 * OCR Evaluation Framework for TTB Label Verification
 *
 * Usage:
 * node scripts/eval-ocr.js --compare      # Side-by-side test results
 * node scripts/eval-ocr.js --extraction   # Field-level comparison
 * node scripts/eval-ocr.js --latency      # Latency benchmark
 * node scripts/eval-ocr.js --ocr-only     # Raw OCR quality
 * node scripts/eval-ocr.js --fallback     # Fallback behavior
 * node scripts/eval-ocr.js --all          # Run all evals
 *
 * Requirements:
 * - Dev server running on localhost:3000
 */

const fs = require('fs');
const path = require('path');

const VISION_API_URL = 'http://localhost:3000/api/verify';
const OCR_API_URL = 'http://localhost:3000/api/verify-ocr';
const TEST_DATA_DIR = path.join(__dirname, '../src/test-data');
const RESULTS_DIR = path.join(__dirname, '../src/test-data/eval-results');

// Parse command line arguments
const ARGS = process.argv.slice(2);
const RUN_COMPARE = ARGS.includes('--compare') || ARGS.includes('--all');
const RUN_EXTRACTION = ARGS.includes('--extraction') || ARGS.includes('--all');
const RUN_LATENCY = ARGS.includes('--latency') || ARGS.includes('--all');
const RUN_OCR_ONLY = ARGS.includes('--ocr-only') || ARGS.includes('--all');
const RUN_FALLBACK = ARGS.includes('--fallback') || ARGS.includes('--all');

// Groups to test (skip advanced DALL-E generated by default)
const INCLUDE_GROUPS = ['basic', 'intermediate', 'stress'];

// Latency thresholds for OCR
const LATENCY_THRESHOLDS = {
  target: 2000,    // 2 seconds - OCR target
  acceptable: 3000, // 3 seconds - acceptable
  max: 5000         // 5 seconds - PRD maximum
};

async function main() {
  if (!RUN_COMPARE && !RUN_EXTRACTION && !RUN_LATENCY && !RUN_OCR_ONLY && !RUN_FALLBACK) {
    console.log('OCR Evaluation Framework');
    console.log('========================\n');
    console.log('Usage:');
    console.log('  node scripts/eval-ocr.js --compare      # Side-by-side test results');
    console.log('  node scripts/eval-ocr.js --extraction   # Field-level comparison');
    console.log('  node scripts/eval-ocr.js --latency      # Latency benchmark');
    console.log('  node scripts/eval-ocr.js --ocr-only     # Raw OCR quality');
    console.log('  node scripts/eval-ocr.js --fallback     # Fallback behavior');
    console.log('  node scripts/eval-ocr.js --all          # Run all evals\n');
    process.exit(0);
  }

  // Check server is running
  const serverRunning = await checkServer();
  if (!serverRunning) {
    console.error('Dev server not running. Start it with: npm run dev\n');
    process.exit(1);
  }

  // Ensure results directory exists
  if (!fs.existsSync(RESULTS_DIR)) {
    fs.mkdirSync(RESULTS_DIR, { recursive: true });
  }

  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  const evalId = `eval-${timestamp}`;

  console.log('OCR Evaluation Framework');
  console.log('========================\n');
  console.log(`Eval ID: ${evalId}`);
  console.log(`Timestamp: ${new Date().toISOString()}\n`);

  // Load test scenarios
  const scenariosPath = path.join(TEST_DATA_DIR, 'sample-applications.json');
  const scenarios = JSON.parse(fs.readFileSync(scenariosPath, 'utf-8'));

  // Filter scenarios by group
  const testCases = scenarios.labels.filter(s => INCLUDE_GROUPS.includes(s.group));
  console.log(`Running ${testCases.length} test cases from groups: ${INCLUDE_GROUPS.join(', ')}\n`);

  const results = {
    evalId,
    timestamp: new Date().toISOString(),
    testCases: testCases.length,
    compare: null,
    extraction: null,
    latency: null,
    ocrOnly: null,
    fallback: null,
  };

  // Run selected evaluations
  if (RUN_COMPARE) {
    console.log('=' .repeat(60));
    console.log('EVAL 1: Side-by-Side Test Results');
    console.log('=' .repeat(60) + '\n');
    results.compare = await runCompareEval(testCases);
  }

  if (RUN_EXTRACTION) {
    console.log('\n' + '='.repeat(60));
    console.log('EVAL 2: Field-Level Extraction Comparison');
    console.log('='.repeat(60) + '\n');
    results.extraction = await runExtractionEval(testCases);
  }

  if (RUN_LATENCY) {
    console.log('\n' + '='.repeat(60));
    console.log('EVAL 3: Latency Benchmark');
    console.log('='.repeat(60) + '\n');
    results.latency = await runLatencyEval(testCases);
  }

  if (RUN_OCR_ONLY) {
    console.log('\n' + '='.repeat(60));
    console.log('EVAL 4: OCR Quality Check');
    console.log('='.repeat(60) + '\n');
    results.ocrOnly = await runOCROnlyEval(testCases);
  }

  if (RUN_FALLBACK) {
    console.log('\n' + '='.repeat(60));
    console.log('EVAL 5: Fallback Behavior');
    console.log('='.repeat(60) + '\n');
    results.fallback = await runFallbackEval(testCases);
  }

  // Save results
  const jsonFile = path.join(RESULTS_DIR, `${evalId}.json`);
  fs.writeFileSync(jsonFile, JSON.stringify(results, null, 2));
  console.log(`\nJSON results saved to: ${jsonFile}`);

  // Generate HTML report
  const htmlReport = generateHTMLReport(results);
  const htmlFile = path.join(RESULTS_DIR, `${evalId}.html`);
  fs.writeFileSync(htmlFile, htmlReport);
  console.log(`HTML report saved to: ${htmlFile}`);

  // Print summary
  printSummary(results);
}

async function checkServer() {
  try {
    const response = await fetch('http://localhost:3000', { method: 'HEAD' });
    return response.ok || response.status === 404; // 404 is ok, means server is up
  } catch {
    return false;
  }
}

async function makeRequest(url, scenario) {
  const pngFileName = scenario.htmlFile.replace('labels/', '').replace('.html', '.png');
  const pngPath = path.join(TEST_DATA_DIR, 'sample-labels', pngFileName);

  if (!fs.existsSync(pngPath)) {
    return { error: `PNG not found: ${pngFileName}` };
  }

  const imageBuffer = fs.readFileSync(pngPath);
  const { FormData, fetch: undiciFetch } = await import('undici');

  const formData = new FormData();
  const blob = new Blob([imageBuffer], { type: 'image/png' });
  formData.set('labelImage', blob, pngFileName);
  formData.set('applicationData', JSON.stringify(scenario.applicationData));

  const startTime = Date.now();
  try {
    const response = await undiciFetch(url, {
      method: 'POST',
      body: formData
    });
    const latencyMs = Date.now() - startTime;

    if (!response.ok) {
      const error = await response.json();
      return { error: error.error || `HTTP ${response.status}`, latencyMs };
    }

    const data = await response.json();
    return { ...data, latencyMs };
  } catch (err) {
    return { error: err.message, latencyMs: Date.now() - startTime };
  }
}

// Eval 1: Side-by-side comparison
async function runCompareEval(testCases) {
  const results = {
    tests: [],
    matching: 0,
    total: 0
  };

  console.log('Test Case                | Vision | OCR    | Match?');
  console.log('-------------------------|--------|--------|--------');

  for (const scenario of testCases) {
    const [visionResult, ocrResult] = await Promise.all([
      makeRequest(VISION_API_URL, scenario),
      makeRequest(OCR_API_URL, scenario)
    ]);

    const visionStatus = visionResult.error ? 'ERROR' : visionResult.overallStatus;
    const ocrStatus = ocrResult.error ? 'ERROR' : ocrResult.overallStatus;

    // Check if they match (or both are acceptable for PASS cases)
    let matches = visionStatus === ocrStatus;
    if (!matches && scenario.expectedResult === 'PASS') {
      // REVIEW is acceptable if only bold warning differs
      if (visionStatus === 'PASS' && ocrStatus === 'REVIEW') {
        const nonBoldWarnings = (ocrResult.fieldResults || []).filter(
          f => (f.status === 'WARNING' || f.status === 'FAIL') &&
               f.fieldName !== 'Gov Warning — Header Bold'
        );
        if (nonBoldWarnings.length === 0) {
          matches = true;
        }
      }
    }

    const matchIcon = matches ? '✅' : '❌';
    console.log(`${scenario.id.padEnd(24)} | ${visionStatus.padEnd(6)} | ${ocrStatus.padEnd(6)} | ${matchIcon}`);

    results.tests.push({
      id: scenario.id,
      expected: scenario.expectedResult,
      vision: visionStatus,
      ocr: ocrStatus,
      matches
    });
    results.total++;
    if (matches) results.matching++;
  }

  console.log(`\nSummary: ${results.matching}/${results.total} matching (${((results.matching / results.total) * 100).toFixed(0)}%)`);

  return results;
}

// Eval 2: Field-level extraction comparison
async function runExtractionEval(testCases) {
  const results = {
    tests: [],
    fieldMatches: {},
    overallAccuracy: 0
  };

  // Track matches per field
  const fieldStats = {};

  for (const scenario of testCases) {
    console.log(`\n=== Test: ${scenario.id} ===\n`);

    const [visionResult, ocrResult] = await Promise.all([
      makeRequest(VISION_API_URL, scenario),
      makeRequest(OCR_API_URL, scenario)
    ]);

    if (visionResult.error || ocrResult.error) {
      console.log(`  Error: Vision=${visionResult.error || 'ok'}, OCR=${ocrResult.error || 'ok'}`);
      continue;
    }

    const testResult = { id: scenario.id, fields: [] };
    const fields = ['brandName', 'classType', 'alcoholContent', 'netContents', 'nameAddress', 'governmentWarning'];

    for (const field of fields) {
      const visionVal = visionResult.extractedFields?.[field] || '(null)';
      const ocrVal = ocrResult.extractedFields?.[field] || '(null)';
      const matches = normalizeForCompare(visionVal) === normalizeForCompare(ocrVal);

      if (!fieldStats[field]) fieldStats[field] = { matches: 0, total: 0 };
      fieldStats[field].total++;
      if (matches) fieldStats[field].matches++;

      const matchIcon = matches ? '✅' : '❌';
      console.log(`Field: ${field}`);
      console.log(`  Vision: ${truncate(visionVal, 60)}`);
      console.log(`  OCR:    ${truncate(ocrVal, 60)}`);
      console.log(`  Match:  ${matchIcon}\n`);

      testResult.fields.push({ field, vision: visionVal, ocr: ocrVal, matches });
    }

    // Compare header format (can differ but both should detect correctly)
    const visionFormat = visionResult.extractedFields?.governmentWarningHeaderFormat;
    const ocrFormat = ocrResult.extractedFields?.governmentWarningHeaderFormat;
    console.log(`Field: governmentWarningHeaderFormat`);
    console.log(`  Vision: ${visionFormat}`);
    console.log(`  OCR:    ${ocrFormat}`);
    console.log(`  Match:  ${visionFormat === ocrFormat ? '✅' : '⚠️ (expected difference)'}\n`);

    // Emphasis - OCR always returns UNCERTAIN, which is expected
    const visionEmphasis = visionResult.extractedFields?.governmentWarningHeaderEmphasis;
    const ocrEmphasis = ocrResult.extractedFields?.governmentWarningHeaderEmphasis;
    console.log(`Field: governmentWarningHeaderEmphasis`);
    console.log(`  Vision: ${visionEmphasis}`);
    console.log(`  OCR:    ${ocrEmphasis}`);
    console.log(`  Match:  ${ocrEmphasis === 'UNCERTAIN' ? '✅ Expected (OCR cannot detect bold)' : '⚠️'}\n`);

    results.tests.push(testResult);
  }

  // Calculate overall accuracy
  let totalMatches = 0;
  let totalFields = 0;
  for (const field of Object.keys(fieldStats)) {
    totalMatches += fieldStats[field].matches;
    totalFields += fieldStats[field].total;
    results.fieldMatches[field] = {
      matches: fieldStats[field].matches,
      total: fieldStats[field].total,
      accuracy: (fieldStats[field].matches / fieldStats[field].total * 100).toFixed(1) + '%'
    };
  }
  results.overallAccuracy = totalFields > 0 ? (totalMatches / totalFields * 100).toFixed(1) + '%' : '0%';

  console.log('\n--- Field Accuracy Summary ---');
  for (const [field, stats] of Object.entries(results.fieldMatches)) {
    console.log(`  ${field}: ${stats.accuracy} (${stats.matches}/${stats.total})`);
  }
  console.log(`\nOverall: ${results.overallAccuracy}`);

  return results;
}

// Eval 3: Latency benchmark
async function runLatencyEval(testCases) {
  const results = {
    tests: [],
    vision: { times: [], avg: 0, min: 0, max: 0, p95: 0 },
    ocr: { times: [], avg: 0, min: 0, max: 0, p95: 0, underTarget: 0 },
    speedup: 0
  };

  console.log('Test Case                | Vision (ms) | OCR (ms) | Speedup');
  console.log('-------------------------|-------------|----------|--------');

  for (const scenario of testCases) {
    const visionResult = await makeRequest(VISION_API_URL, scenario);
    const ocrResult = await makeRequest(OCR_API_URL, scenario);

    const visionMs = visionResult.latencyMs || 0;
    const ocrMs = ocrResult.latencyMs || 0;
    const speedup = visionMs > 0 ? (visionMs / ocrMs).toFixed(1) : 'N/A';

    console.log(`${scenario.id.padEnd(24)} | ${String(visionMs).padStart(11)} | ${String(ocrMs).padStart(8)} | ${speedup}x`);

    results.tests.push({
      id: scenario.id,
      visionMs,
      ocrMs,
      speedup: parseFloat(speedup) || 0
    });

    if (visionMs > 0) results.vision.times.push(visionMs);
    if (ocrMs > 0) {
      results.ocr.times.push(ocrMs);
      if (ocrMs < LATENCY_THRESHOLDS.target) results.ocr.underTarget++;
    }
  }

  // Calculate stats
  if (results.vision.times.length > 0) {
    const sorted = [...results.vision.times].sort((a, b) => a - b);
    results.vision.min = sorted[0];
    results.vision.max = sorted[sorted.length - 1];
    results.vision.avg = Math.round(sorted.reduce((a, b) => a + b, 0) / sorted.length);
    results.vision.p95 = sorted[Math.floor(sorted.length * 0.95)] || sorted[sorted.length - 1];
  }

  if (results.ocr.times.length > 0) {
    const sorted = [...results.ocr.times].sort((a, b) => a - b);
    results.ocr.min = sorted[0];
    results.ocr.max = sorted[sorted.length - 1];
    results.ocr.avg = Math.round(sorted.reduce((a, b) => a + b, 0) / sorted.length);
    results.ocr.p95 = sorted[Math.floor(sorted.length * 0.95)] || sorted[sorted.length - 1];
  }

  results.speedup = results.vision.avg > 0 ? (results.vision.avg / results.ocr.avg).toFixed(1) : 'N/A';

  console.log(`\nAverage Vision: ${results.vision.avg}ms`);
  console.log(`Average OCR:    ${results.ocr.avg}ms`);
  console.log(`Speedup:        ${results.speedup}x`);
  console.log(`\nOCR < ${LATENCY_THRESHOLDS.target}ms for all tests: ${results.ocr.underTarget === results.ocr.times.length ? '✅' : '❌'} (${results.ocr.underTarget}/${results.ocr.times.length})`);

  return results;
}

// Eval 4: OCR quality check
async function runOCROnlyEval(testCases) {
  const results = {
    tests: [],
    avgConfidence: 0,
    hasWarning: 0,
    hasABV: 0,
    total: 0
  };

  console.log('Test Case                | Confidence | Text Length | Has Warning? | Has ABV?');
  console.log('-------------------------|------------|-------------|--------------|----------');

  for (const scenario of testCases) {
    const ocrResult = await makeRequest(OCR_API_URL, scenario);

    if (ocrResult.error) {
      console.log(`${scenario.id.padEnd(24)} | ERROR: ${ocrResult.error}`);
      continue;
    }

    const confidence = ocrResult.ocrConfidence || 0;
    const textLength = ocrResult.extractedFields?.governmentWarning?.length || 0;
    const hasWarning = ocrResult.extractedFields?.governmentWarning ? true : false;
    const hasABV = ocrResult.extractedFields?.alcoholContent ? true : false;

    console.log(`${scenario.id.padEnd(24)} | ${(confidence.toFixed(0) + '%').padStart(10)} | ${String(textLength + ' chars').padStart(11)} | ${hasWarning ? '✅' : '❌'}            | ${hasABV ? '✅' : '❌'}`);

    results.tests.push({
      id: scenario.id,
      confidence,
      textLength,
      hasWarning,
      hasABV,
      usedFallback: ocrResult.timing?.usedFallback || false,
      fallbackReason: ocrResult.timing?.fallbackReason
    });

    results.total++;
    if (hasWarning) results.hasWarning++;
    if (hasABV) results.hasABV++;
  }

  // Calculate average confidence (only for non-fallback results)
  const nonFallback = results.tests.filter(t => !t.usedFallback);
  if (nonFallback.length > 0) {
    results.avgConfidence = nonFallback.reduce((a, t) => a + t.confidence, 0) / nonFallback.length;
  }

  console.log(`\nAverage Confidence (non-fallback): ${results.avgConfidence.toFixed(1)}%`);
  console.log(`Has Warning: ${results.hasWarning}/${results.total}`);
  console.log(`Has ABV: ${results.hasABV}/${results.total}`);

  return results;
}

// Eval 5: Fallback behavior
async function runFallbackEval(testCases) {
  const results = {
    tests: [],
    fallbackCount: 0,
    total: 0
  };

  console.log('Scenario                      | OCR Conf | Fallback? | Final Result');
  console.log('------------------------------|----------|-----------|-------------');

  for (const scenario of testCases) {
    const ocrResult = await makeRequest(OCR_API_URL, scenario);

    if (ocrResult.error) {
      console.log(`${scenario.id.padEnd(29)} | ERROR: ${ocrResult.error}`);
      continue;
    }

    const confidence = ocrResult.ocrConfidence || 0;
    const usedFallback = ocrResult.timing?.usedFallback || false;
    const status = ocrResult.overallStatus;

    console.log(`${scenario.id.padEnd(29)} | ${(confidence.toFixed(0) + '%').padStart(8)} | ${usedFallback ? 'Yes' : 'No'.padEnd(9)} | ${usedFallback ? 'Vision' : 'OCR'} → ${status}`);

    results.tests.push({
      id: scenario.id,
      confidence,
      usedFallback,
      fallbackReason: ocrResult.timing?.fallbackReason,
      status
    });

    results.total++;
    if (usedFallback) results.fallbackCount++;
  }

  console.log(`\nFallback triggered: ${results.fallbackCount}/${results.total} (${((results.fallbackCount / results.total) * 100).toFixed(0)}%)`);

  return results;
}

// Helper functions
function normalizeForCompare(str) {
  if (!str) return '';
  return str.toLowerCase().replace(/\s+/g, ' ').trim();
}

function truncate(str, len) {
  if (!str) return '(null)';
  if (str.length <= len) return str;
  return str.substring(0, len - 3) + '...';
}

function printSummary(results) {
  console.log('\n' + '='.repeat(60));
  console.log('EVALUATION SUMMARY');
  console.log('='.repeat(60) + '\n');

  console.log('| Metric | Required | Actual | Ship? |');
  console.log('|--------|----------|--------|-------|');

  if (results.compare) {
    const rate = (results.compare.matching / results.compare.total * 100).toFixed(0) + '%';
    const ship = results.compare.matching === results.compare.total ? '✅' : '❌';
    console.log(`| Test result match | 100% | ${rate} | ${ship} |`);
  }

  if (results.extraction) {
    const ship = parseFloat(results.extraction.overallAccuracy) >= 95 ? '✅' : '❌';
    console.log(`| Extraction accuracy | >95% | ${results.extraction.overallAccuracy} | ${ship} |`);
  }

  if (results.latency) {
    const avgShip = results.latency.ocr.avg < 2000 ? '✅' : '❌';
    const p95Ship = results.latency.ocr.p95 < 3000 ? '✅' : '❌';
    console.log(`| Latency avg | <2000ms | ${results.latency.ocr.avg}ms | ${avgShip} |`);
    console.log(`| Latency p95 | <3000ms | ${results.latency.ocr.p95}ms | ${p95Ship} |`);
  }

  if (results.fallback) {
    console.log(`| Fallback works | Yes | Yes | ✅ |`);
  }

  console.log('');
}

function generateHTMLReport(results) {
  let compareHTML = '';
  if (results.compare) {
    const rows = results.compare.tests.map(t => `
      <tr class="${t.matches ? 'pass' : 'fail'}">
        <td>${t.id}</td>
        <td>${t.expected}</td>
        <td>${t.vision}</td>
        <td>${t.ocr}</td>
        <td>${t.matches ? '✅' : '❌'}</td>
      </tr>
    `).join('');

    compareHTML = `
      <h2>Eval 1: Side-by-Side Test Results</h2>
      <p class="summary ${results.compare.matching === results.compare.total ? 'pass' : 'fail'}">
        Match Rate: ${results.compare.matching}/${results.compare.total} (${((results.compare.matching / results.compare.total) * 100).toFixed(0)}%)
      </p>
      <table>
        <thead>
          <tr><th>Test Case</th><th>Expected</th><th>Vision</th><th>OCR</th><th>Match?</th></tr>
        </thead>
        <tbody>${rows}</tbody>
      </table>
    `;
  }

  let latencyHTML = '';
  if (results.latency) {
    const rows = results.latency.tests.map(t => `
      <tr>
        <td>${t.id}</td>
        <td>${t.visionMs}ms</td>
        <td class="${t.ocrMs < 2000 ? 'fast' : t.ocrMs < 3000 ? 'medium' : 'slow'}">${t.ocrMs}ms</td>
        <td>${t.speedup}x</td>
      </tr>
    `).join('');

    latencyHTML = `
      <h2>Eval 3: Latency Benchmark</h2>
      <div class="stats">
        <div class="stat">
          <div class="label">Vision Avg</div>
          <div class="value">${results.latency.vision.avg}ms</div>
        </div>
        <div class="stat">
          <div class="label">OCR Avg</div>
          <div class="value ${results.latency.ocr.avg < 2000 ? 'pass' : 'fail'}">${results.latency.ocr.avg}ms</div>
        </div>
        <div class="stat">
          <div class="label">OCR P95</div>
          <div class="value ${results.latency.ocr.p95 < 3000 ? 'pass' : 'fail'}">${results.latency.ocr.p95}ms</div>
        </div>
        <div class="stat">
          <div class="label">Speedup</div>
          <div class="value">${results.latency.speedup}x</div>
        </div>
      </div>
      <table>
        <thead>
          <tr><th>Test Case</th><th>Vision</th><th>OCR</th><th>Speedup</th></tr>
        </thead>
        <tbody>${rows}</tbody>
      </table>
    `;
  }

  let fallbackHTML = '';
  if (results.fallback) {
    const rows = results.fallback.tests.map(t => `
      <tr>
        <td>${t.id}</td>
        <td>${t.confidence.toFixed(0)}%</td>
        <td>${t.usedFallback ? 'Yes' : 'No'}</td>
        <td>${t.status}</td>
        <td>${t.fallbackReason || '-'}</td>
      </tr>
    `).join('');

    fallbackHTML = `
      <h2>Eval 5: Fallback Behavior</h2>
      <p class="summary">
        Fallback triggered: ${results.fallback.fallbackCount}/${results.fallback.total}
      </p>
      <table>
        <thead>
          <tr><th>Test Case</th><th>OCR Conf</th><th>Fallback?</th><th>Result</th><th>Reason</th></tr>
        </thead>
        <tbody>${rows}</tbody>
      </table>
    `;
  }

  return `<!DOCTYPE html>
<html>
<head>
  <title>OCR Evaluation - ${results.evalId}</title>
  <style>
    body { font-family: -apple-system, sans-serif; padding: 20px; max-width: 1200px; margin: 0 auto; }
    h1 { color: #333; }
    h2 { color: #555; margin-top: 40px; }
    table { width: 100%; border-collapse: collapse; margin: 20px 0; }
    th, td { padding: 10px; text-align: left; border-bottom: 1px solid #ddd; }
    th { background: #f5f5f5; }
    tr.pass { background: #f0fdf4; }
    tr.fail { background: #fef2f2; }
    .summary { font-size: 1.2em; padding: 10px; border-radius: 8px; }
    .summary.pass { background: #dcfce7; color: #166534; }
    .summary.fail { background: #fee2e2; color: #991b1b; }
    .stats { display: flex; gap: 20px; margin: 20px 0; }
    .stat { background: #f5f5f5; padding: 15px 25px; border-radius: 8px; text-align: center; }
    .stat .label { color: #666; font-size: 0.9em; }
    .stat .value { font-size: 1.5em; font-weight: bold; }
    .stat .value.pass { color: #22c55e; }
    .stat .value.fail { color: #ef4444; }
    .fast { color: #22c55e; }
    .medium { color: #f59e0b; }
    .slow { color: #ef4444; }
  </style>
</head>
<body>
  <h1>OCR Evaluation Report</h1>
  <p><strong>Eval ID:</strong> ${results.evalId}</p>
  <p><strong>Timestamp:</strong> ${results.timestamp}</p>
  <p><strong>Test Cases:</strong> ${results.testCases}</p>

  ${compareHTML}
  ${latencyHTML}
  ${fallbackHTML}
</body>
</html>`;
}

main().catch(console.error);
